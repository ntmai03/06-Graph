{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for text / string processing\n",
    "import re\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Modelling Helpers:\n",
    "# from sklearn.preprocessing import Imputer, Normalizer, scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, ShuffleSplit, cross_validate\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# for tree binarisation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Evaluation metrics for Classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Regression\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV,ElasticNet,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "# Evaluation metrics for Regression \n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, accuracy_score, roc_auc_score, auc,\n",
    "                             precision_score, recall_score, roc_curve, precision_recall_curve,\n",
    "                             precision_recall_fscore_support, f1_score,\n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 17), (223, 17))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "train_df = pd.read_csv('preprocessed_Train.csv')\n",
    "test_df = pd.read_csv('preprocessed_Test.csv')\n",
    "(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_numerical</th>\n",
       "      <th>Cabin_categorical</th>\n",
       "      <th>Ticket_numerical</th>\n",
       "      <th>Ticket_categorical</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>is_mother</th>\n",
       "      <th>Age_NA</th>\n",
       "      <th>Ticket_numerical_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.345603</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.153646</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.345603</td>\n",
       "      <td>157.888732</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.706767</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.345603</td>\n",
       "      <td>157.888732</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.706767</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.345603</td>\n",
       "      <td>157.888732</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.345603</td>\n",
       "      <td>157.888732</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.153646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked  \\\n",
       "0         0       1    1  31.0      1      0  0.500000  0.345603   \n",
       "1         1       2    0  18.0      0      2  0.416667  0.345603   \n",
       "2         0       3    0   9.0      3      2  0.450000  0.345603   \n",
       "3         1       2    0  22.0      1      1  0.450000  0.345603   \n",
       "4         0       3    1  19.0      0      0  0.212500  0.345603   \n",
       "\n",
       "   Cabin_numerical  Cabin_categorical  Ticket_numerical  Ticket_categorical  \\\n",
       "0        71.000000           0.720930          0.421687            0.342857   \n",
       "1       157.888732           0.304348          0.279070            0.382114   \n",
       "2       157.888732           0.304348          0.123457            0.382114   \n",
       "3       157.888732           0.304348          0.279070            0.382114   \n",
       "4       157.888732           0.304348          0.279070            0.382114   \n",
       "\n",
       "      Title  Family_size  is_mother  Age_NA  Ticket_numerical_NA  \n",
       "0  0.153646            2          0       0                    0  \n",
       "1  0.706767            3          0       0                    0  \n",
       "2  0.706767            6          0       0                    0  \n",
       "3  0.795918            3          1       0                    0  \n",
       "4  0.153646            1          0       0                    0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare',\n",
       " 'Embarked',\n",
       " 'Cabin_numerical',\n",
       " 'Cabin_categorical',\n",
       " 'Ticket_numerical',\n",
       " 'Ticket_categorical',\n",
       " 'Title',\n",
       " 'Family_size',\n",
       " 'is_mother',\n",
       " 'Age_NA',\n",
       " 'Ticket_numerical_NA']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vars = [var for var in train_df.columns if var not in ['PassengerId', 'Survived']]\n",
    "training_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[training_vars]\n",
    "y_train = train_df['Survived']\n",
    "X_test = test_df[training_vars]\n",
    "y_test = test_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit scaler\n",
    "scaler = MinMaxScaler() # create an instance\n",
    "scaler.fit(X_train[training_vars]) #  fit  the scaler to the train set and then transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.transform(X_train[training_vars]),columns=training_vars)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test[training_vars]),columns=training_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_numerical</th>\n",
       "      <th>Cabin_categorical</th>\n",
       "      <th>Ticket_numerical</th>\n",
       "      <th>Ticket_categorical</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>is_mother</th>\n",
       "      <th>Age_NA</th>\n",
       "      <th>Ticket_numerical_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.648204</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>0.165419</td>\n",
       "      <td>0.420659</td>\n",
       "      <td>0.201604</td>\n",
       "      <td>0.850257</td>\n",
       "      <td>0.177012</td>\n",
       "      <td>0.537077</td>\n",
       "      <td>0.567536</td>\n",
       "      <td>0.357461</td>\n",
       "      <td>0.139222</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.477889</td>\n",
       "      <td>0.197311</td>\n",
       "      <td>0.225467</td>\n",
       "      <td>0.323889</td>\n",
       "      <td>0.300766</td>\n",
       "      <td>0.385105</td>\n",
       "      <td>0.297637</td>\n",
       "      <td>0.350903</td>\n",
       "      <td>0.300230</td>\n",
       "      <td>0.173565</td>\n",
       "      <td>0.435625</td>\n",
       "      <td>0.236045</td>\n",
       "      <td>0.253410</td>\n",
       "      <td>0.402971</td>\n",
       "      <td>0.066915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321723</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483136</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517773</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.194021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772260</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>0.861194</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Sex         Age       SibSp       Parch        Fare  \\\n",
       "count  668.000000  668.000000  668.000000  668.000000  668.000000  668.000000   \n",
       "mean     0.649701    0.648204    0.407217    0.118263    0.165419    0.420659   \n",
       "std      0.420662    0.477889    0.197311    0.225467    0.323889    0.300766   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.500000    0.000000    0.269771    0.000000    0.000000    0.144608   \n",
       "50%      1.000000    1.000000    0.393772    0.000000    0.000000    0.441860   \n",
       "75%      1.000000    1.000000    0.517773    0.250000    0.000000    0.537500   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Embarked  Cabin_numerical  Cabin_categorical  Ticket_numerical  \\\n",
       "count  668.000000       668.000000         668.000000        668.000000   \n",
       "mean     0.201604         0.850257           0.177012          0.537077   \n",
       "std      0.385105         0.297637           0.350903          0.300230   \n",
       "min      0.000000         0.000000           0.000000          0.000000   \n",
       "25%      0.000000         1.000000           0.000000          0.321723   \n",
       "50%      0.000000         1.000000           0.000000          0.483136   \n",
       "75%      0.194021         1.000000           0.000000          0.772260   \n",
       "max      1.000000         1.000000           1.000000          1.000000   \n",
       "\n",
       "       Ticket_categorical       Title  Family_size   is_mother      Age_NA  \\\n",
       "count          668.000000  668.000000   668.000000  668.000000  668.000000   \n",
       "mean             0.567536    0.357461     0.139222    0.068862    0.203593   \n",
       "std              0.173565    0.435625     0.236045    0.253410    0.402971   \n",
       "min              0.000000    0.000000     0.000000    0.000000    0.000000   \n",
       "25%              0.565577    0.000000     0.000000    0.000000    0.000000   \n",
       "50%              0.565577    0.000000     0.000000    0.000000    0.000000   \n",
       "75%              0.565577    0.861194     0.166667    0.000000    0.000000   \n",
       "max              1.000000    1.000000     1.000000    1.000000    1.000000   \n",
       "\n",
       "       Ticket_numerical_NA  \n",
       "count           668.000000  \n",
       "mean              0.004491  \n",
       "std               0.066915  \n",
       "min               0.000000  \n",
       "25%               0.000000  \n",
       "50%               0.000000  \n",
       "75%               0.000000  \n",
       "max               1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_numerical</th>\n",
       "      <th>Cabin_categorical</th>\n",
       "      <th>Ticket_numerical</th>\n",
       "      <th>Ticket_categorical</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>is_mother</th>\n",
       "      <th>Age_NA</th>\n",
       "      <th>Ticket_numerical_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>223.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.668161</td>\n",
       "      <td>0.645740</td>\n",
       "      <td>0.406176</td>\n",
       "      <td>0.131166</td>\n",
       "      <td>0.195067</td>\n",
       "      <td>0.428087</td>\n",
       "      <td>0.216450</td>\n",
       "      <td>0.830670</td>\n",
       "      <td>0.118402</td>\n",
       "      <td>0.522291</td>\n",
       "      <td>0.553289</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.159940</td>\n",
       "      <td>0.080717</td>\n",
       "      <td>0.183857</td>\n",
       "      <td>0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.410690</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.207786</td>\n",
       "      <td>0.232262</td>\n",
       "      <td>0.353646</td>\n",
       "      <td>0.278005</td>\n",
       "      <td>0.393531</td>\n",
       "      <td>0.333742</td>\n",
       "      <td>0.295223</td>\n",
       "      <td>0.308579</td>\n",
       "      <td>0.183407</td>\n",
       "      <td>0.437591</td>\n",
       "      <td>0.252772</td>\n",
       "      <td>0.273014</td>\n",
       "      <td>0.388239</td>\n",
       "      <td>0.066965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321723</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616578</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.524662</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.194021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766032</td>\n",
       "      <td>0.565577</td>\n",
       "      <td>0.861194</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Sex         Age       SibSp       Parch        Fare  \\\n",
       "count  223.000000  223.000000  223.000000  223.000000  223.000000  223.000000   \n",
       "mean     0.668161    0.645740    0.406176    0.131166    0.195067    0.428087   \n",
       "std      0.410690    0.479365    0.207786    0.232262    0.353646    0.278005   \n",
       "min      0.000000    0.000000    0.004547    0.000000    0.000000    0.000000   \n",
       "25%      0.500000    0.000000    0.283549    0.000000    0.000000    0.144608   \n",
       "50%      1.000000    1.000000    0.379994    0.000000    0.000000    0.479167   \n",
       "75%      1.000000    1.000000    0.524662    0.250000    0.500000    0.625000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Embarked  Cabin_numerical  Cabin_categorical  Ticket_numerical  \\\n",
       "count  223.000000       223.000000         223.000000        223.000000   \n",
       "mean     0.216450         0.830670           0.118402          0.522291   \n",
       "std      0.393531         0.333742           0.295223          0.308579   \n",
       "min      0.000000         0.000000           0.000000          0.000000   \n",
       "25%      0.000000         1.000000           0.000000          0.321723   \n",
       "50%      0.000000         1.000000           0.000000          0.616578   \n",
       "75%      0.194021         1.000000           0.000000          0.766032   \n",
       "max      1.000000         1.000000           1.000000          1.000000   \n",
       "\n",
       "       Ticket_categorical       Title  Family_size   is_mother      Age_NA  \\\n",
       "count          223.000000  223.000000   223.000000  223.000000  223.000000   \n",
       "mean             0.553289    0.345238     0.159940    0.080717    0.183857   \n",
       "std              0.183407    0.437591     0.252772    0.273014    0.388239   \n",
       "min              0.000000    0.000000     0.000000    0.000000    0.000000   \n",
       "25%              0.565577    0.000000     0.000000    0.000000    0.000000   \n",
       "50%              0.565577    0.000000     0.000000    0.000000    0.000000   \n",
       "75%              0.565577    0.861194     0.250000    0.000000    0.000000   \n",
       "max              1.000000    1.000000     1.000000    1.000000    1.000000   \n",
       "\n",
       "       Ticket_numerical_NA  \n",
       "count           223.000000  \n",
       "mean              0.004484  \n",
       "std               0.066965  \n",
       "min               0.000000  \n",
       "25%               0.000000  \n",
       "50%               0.000000  \n",
       "75%               0.000000  \n",
       "max               1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8517964071856288\n",
      "xgb train roc-auc: 0.916091474514563\n",
      "Test Accuracy:  0.7802690582959642\n",
      "xgb test roc-auc: 0.828509590901375\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict_proba(X_train[training_vars])\n",
    "y_train_pred = model.predict(X_train[training_vars])\n",
    "print('Train Accuracy: ', accuracy_score(y_train, list(y_train_pred)))\n",
    "print('xgb train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "pred = model.predict_proba(X_test[training_vars])\n",
    "y_test_pred = model.predict(X_test[training_vars])\n",
    "print('Test Accuracy: ', accuracy_score(y_test, list(y_test_pred)))\n",
    "print('xgb test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       412\n",
      "           1       0.81      0.80      0.81       256\n",
      "\n",
      "    accuracy                           0.85       668\n",
      "   macro avg       0.84      0.84      0.84       668\n",
      "weighted avg       0.85      0.85      0.85       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, list(y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       137\n",
      "           1       0.73      0.67      0.70        86\n",
      "\n",
      "    accuracy                           0.78       223\n",
      "   macro avg       0.77      0.76      0.76       223\n",
      "weighted avg       0.78      0.78      0.78       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, list(y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select threshold for maximum accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.68466398, 0.68466398, 0.68046699, 0.66033496, 0.65820017,\n",
       "       0.65355296, 0.52250748, 0.522319  , 0.51535647, 0.51461182,\n",
       "       0.51246006, 0.51214162, 0.51044827, 0.51025195, 0.50947767,\n",
       "       0.50940736, 0.50801475, 0.50672818, 0.50608177, 0.50567199,\n",
       "       0.5051298 , 0.50502315, 0.5045607 , 0.50385035, 0.50342085,\n",
       "       0.50322487, 0.50309831, 0.50221176, 0.50205007, 0.50174981,\n",
       "       0.50157905, 0.50055938, 0.50050696, 0.50029202, 0.49954053,\n",
       "       0.49947556, 0.49718431, 0.49694099, 0.49687136, 0.49686743,\n",
       "       0.49685875, 0.49685856, 0.4966358 , 0.49662573, 0.4954656 ,\n",
       "       0.49515439, 0.49389897, 0.49369659, 0.49367457, 0.49332833,\n",
       "       0.4933112 , 0.49308242, 0.49273026, 0.49250963, 0.49243382,\n",
       "       0.49243074, 0.49237789, 0.49116935, 0.49115768, 0.49022657,\n",
       "       0.49011541, 0.48987288, 0.48949781, 0.48888871, 0.48877941,\n",
       "       0.48859492, 0.48844733, 0.48787568, 0.48780084, 0.48761489,\n",
       "       0.48757655, 0.48733851, 0.4869934 , 0.48698787, 0.48649796,\n",
       "       0.48627517, 0.48617985, 0.48615878, 0.48597156, 0.48567797,\n",
       "       0.48566469, 0.48506096, 0.48496736, 0.48478799, 0.48476078,\n",
       "       0.48460188, 0.48441309, 0.48360055, 0.48349235, 0.48317687,\n",
       "       0.48311647, 0.4822849 , 0.48227325, 0.48222841, 0.481597  ,\n",
       "       0.48115698, 0.48098971, 0.47647563, 0.47622878, 0.4713805 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr, tpr, thresholds = metrics.roc_curve(y_test, pred[:,1])\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.501750</td>\n",
       "      <td>0.793722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.504561</td>\n",
       "      <td>0.793722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.503850</td>\n",
       "      <td>0.793722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.503225</td>\n",
       "      <td>0.793722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.501579</td>\n",
       "      <td>0.789238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "29    0.501750  0.793722\n",
       "22    0.504561  0.793722\n",
       "23    0.503850  0.793722\n",
       "25    0.503225  0.793722\n",
       "30    0.501579  0.789238"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(pred[:,1]>thres,1,0)\n",
    "    accuracy_ls.append(metrics.accuracy_score(y_test, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d61c27aac8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHECAYAAADLQ7euAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeZhkZXn///eHQUAxuDEaA4yg4gIuoCPiEtwVNYIxEiAxwS3oLy4YYxIwfiEOcYlJTIziQiJoUIMa1EwURaOICyIMghBQ4ohEJhg3EIkiOHD//jinmJoz3dM10N3nVPN+XVdf1DlV1XMP0131qec8z/2kqpAkSZK0wVZ9FyBJkiQNjSFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkjq37LqBrxx13rF133bXvMiRJkrTEnXvuuT+qquUz3Te4kLzrrruyZs2avsuQJEnSEpfkv2e7z+kWkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkjq37LuCW2PXIT8z797zsjU+f9+8pSZKk6eJIsiRJktRhSJYkSZI6DMmSJElSx0QhOcn+SS5JsjbJkTPc/+IkFyY5P8mXkuzRnt81ybXt+fOTvHO+/wKSJEnSfJtz4V6SZcBxwJOAdcA5SVZX1cVjD/tAVb2zffwBwJuB/dv7vl1Ve81v2ZIkSdLCmWQkeR9gbVVdWlXXAycDB44/oKp+Ona4PVDzV6IkSZK0uCYJyTsBl48dr2vPbSTJS5J8G3gT8PKxu3ZLcl6SM5L8+i2qVpIkSVoEk4TkzHBuk5Hiqjququ4F/Bnwmvb094AVVbU38ErgA0l22OQPSA5PsibJmh/+8IeTVy9JkiQtgElC8jpgl7HjnYErNvP4k4FnAlTVdVX14/b2ucC3gft0n1BVx1fVyqpauXz58klrlyRJkhbEJCH5HGD3JLsl2QY4BFg9/oAku48dPh34Vnt+ebvwjyT3BHYHLp2PwiVJkqSFMmd3i6pan+SlwGnAMuCEqrooySpgTVWtBl6a5InAL4GrgMPap+8HrEqyHrgBeHFVXbkQfxFJkiRpvswZkgGq6lTg1M65o8duHzHL804BTrklBUqSJEmLzR33JEmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqcOQLEmSJHUYkiVJkqQOQ7IkSZLUYUiWJEmSOgzJkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjomCslJ9k9ySZK1SY6c4f4XJ7kwyflJvpRkj7H7jmqfd0mSp8xn8ZIkSdJCmDMkJ1kGHAc8FdgDOHQ8BLc+UFUPrKq9gDcBb26fuwdwCLAnsD/w9vb7SZIkSYM1yUjyPsDaqrq0qq4HTgYOHH9AVf107HB7oNrbBwInV9V1VfUdYG37/SRJkqTB2nqCx+wEXD52vA54ePdBSV4CvBLYBnj82HPP6jx3pxmeezhwOMCKFSsmqVuSJElaMJOMJGeGc7XJiarjqupewJ8Br9nC5x5fVSurauXy5csnKEmSJElaOJOE5HXALmPHOwNXbObxJwPPvJnPlSRJkno3SUg+B9g9yW5JtqFZiLd6/AFJdh87fDrwrfb2auCQJNsm2Q3YHTj7lpctSZIkLZw55yRX1fokLwVOA5YBJ1TVRUlWAWuqajXw0iRPBH4JXAUc1j73oiQfAi4G1gMvqaobFujvIkmSJM2LSRbuUVWnAqd2zh09dvuIzTz3dcDrbm6BkiRJ0mJzxz1JkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqcOQLEmSJHUYkiVJkqQOQ7IkSZLUYUiWJEmSOgzJkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1TBSSk+yf5JIka5McOcP9r0xycZILknw2yT3G7rshyfnt1+r5LF6SJElaCFvP9YAky4DjgCcB64BzkqyuqovHHnYesLKqfp7k/wPeBBzc3ndtVe01z3VLkiRJC2aSkeR9gLVVdWlVXQ+cDBw4/oCqOr2qft4engXsPL9lSpIkSYtnkpC8E3D52PG69txsXgB8cux4uyRrkpyV5Jk3o0ZJkiRpUc053QLIDOdqxgcmzwFWAo8ZO72iqq5Ick/gc0kurKpvd553OHA4wIoVKyYqXJIkSVook4wkrwN2GTveGbii+6AkTwT+HDigqq4bna+qK9r/Xgp8Hti7+9yqOr6qVlbVyuXLl2/RX0CSJEmab5OE5HOA3ZPslmQb4BBgoy4VSfYG3kUTkH8wdv5OSbZtb+8IPAoYX/AnSZIkDc6c0y2qan2SlwKnAcuAE6rqoiSrgDVVtRr4a+D2wIeTAHy3qg4A7g+8K8mNNIH8jZ2uGJIkSdLgTDInmao6FTi1c+7osdtPnOV5ZwIPvCUFSpIkSYvNHfckSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqcOQLEmSJHUYkiVJkqQOQ7IkSZLUYUiWJEmSOgzJkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqcOQLEmSJHUYkiVJkqQOQ7IkSZLUMVFITrJ/kkuSrE1y5Az3vzLJxUkuSPLZJPcYu++wJN9qvw6bz+IlSZKkhTBnSE6yDDgOeCqwB3Bokj06DzsPWFlVDwL+FXhT+9w7A8cADwf2AY5Jcqf5K1+SJEmaf5OMJO8DrK2qS6vqeuBk4MDxB1TV6VX18/bwLGDn9vZTgM9U1ZVVdRXwGWD/+SldkiRJWhiThOSdgMvHjte152bzAuCTN/O5kiRJUu+2nuAxmeFczfjA5DnASuAxW/LcJIcDhwOsWLFigpIkSZKkhTPJSPI6YJex452BK7oPSvJE4M+BA6rqui15blUdX1Urq2rl8uXLJ61dkiRJWhCThORzgN2T7JZkG+AQYPX4A5LsDbyLJiD/YOyu04AnJ7lTu2Dvye05SZIkabDmnG5RVeuTvJQm3C4DTqiqi5KsAtZU1Wrgr4HbAx9OAvDdqjqgqq5McixN0AZYVVVXLsjfRJIkSZonk8xJpqpOBU7tnDt67PYTN/PcE4ATbm6BkiRJ0mJzxz1JkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqcOQLEmSJHUYkiVJkqQOQ7IkSZLUYUiWJEmSOgzJkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6tu67gFuDXY/8xLx/z8ve+PR5/56SJElqOJIsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6JgrJSfZPckmStUmOnOH+/ZJ8Lcn6JM/u3HdDkvPbr9XzVbgkSZK0UObsbpFkGXAc8CRgHXBOktVVdfHYw74LPBd41Qzf4tqq2mseapUkSZIWxSQt4PYB1lbVpQBJTgYOBG4KyVV1WXvfjQtQoyRJkrSoJplusRNw+djxuvbcpLZLsibJWUmeuUXVSZIkST2YZCQ5M5yrLfgzVlTVFUnuCXwuyYVV9e2N/oDkcOBwgBUrVmzBt5YkSZLm3yQjyeuAXcaOdwaumPQPqKor2v9eCnwe2HuGxxxfVSurauXy5csn/daSJEnSgpgkJJ8D7J5ktyTbAIcAE3WpSHKnJNu2t3cEHsXYXGZJkiRpiOYMyVW1HngpcBrwDeBDVXVRklVJDgBI8rAk64CDgHcluah9+v2BNUm+DpwOvLHTFUOSJEkanEnmJFNVpwKnds4dPXb7HJppGN3nnQk88BbWKEmSJC0qd9yTJEmSOgzJkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqWPrvgvQcOx65Cfm/Xte9sanz/v3lCRJWmiOJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkjolCcpL9k1ySZG2SI2e4f78kX0uyPsmzO/cdluRb7ddh81W4JEmStFDmDMlJlgHHAU8F9gAOTbJH52HfBZ4LfKDz3DsDxwAPB/YBjklyp1tetiRJkrRwJhlJ3gdYW1WXVtX1wMnAgeMPqKrLquoC4MbOc58CfKaqrqyqq4DPAPvPQ92SJEnSgpkkJO8EXD52vK49N4lb8lxJkiSpF5OE5Mxwrib8/hM9N8nhSdYkWfPDH/5wwm8tSZIkLYxJQvI6YJex452BKyb8/hM9t6qOr6qVVbVy+fLlE35rSZIkaWFMEpLPAXZPsluSbYBDgNUTfv/TgCcnuVO7YO/J7TlJkiRpsOYMyVW1HngpTbj9BvChqrooyaokBwAkeViSdcBBwLuSXNQ+90rgWJqgfQ6wqj0nSZIkDdbWkzyoqk4FTu2cO3rs9jk0Uylmeu4JwAm3oEZJkiRpUbnjniRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqcOQLEmSJHUYkiVJkqQOQ7IkSZLUYUiWJEmSOgzJkiRJUochWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKlj674LkLbErkd+Yt6/52VvfPq8f89pqVOSJM3MkWRJkiSpw5AsSZIkdRiSJUmSpI6JQnKS/ZNckmRtkiNnuH/bJB9s7/9qkl3b87smuTbJ+e3XO+e3fEmSJGn+zblwL8ky4DjgScA64Jwkq6vq4rGHvQC4qqruneQQ4K+Ag9v7vl1Ve81z3ZIkSdKCmWQkeR9gbVVdWlXXAycDB3YecyDw3vb2vwJPSJL5K1OSJElaPJOE5J2Ay8eO17XnZnxMVa0Hrgbu0t63W5LzkpyR5NdvYb2SJEnSgpukT/JMI8I14WO+B6yoqh8neSjwsSR7VtVPN3pycjhwOMCKFSsmKEmSJElaOJOMJK8Ddhk73hm4YrbHJNkauANwZVVdV1U/Bqiqc4FvA/fp/gFVdXxVrayqlcuXL9/yv4UkSZI0jyYJyecAuyfZLck2wCHA6s5jVgOHtbefDXyuqirJ8nbhH0nuCewOXDo/pUuSJEkLY87pFlW1PslLgdOAZcAJVXVRklXAmqpaDbwbOCnJWuBKmiANsB+wKsl64AbgxVV15UL8RSRJkqT5MsmcZKrqVODUzrmjx27/AjhohuedApxyC2uUJEmSFpU77kmSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpI6JFu5JWpp2PfIT8/49L3vj0+f9e1qnJGmxOZIsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1GJIlSZKkDkOyJEmS1GFIliRJkjoMyZIkSVKHIVmSJEnqMCRLkiRJHYZkSZIkqWPrvguQJC2uXY/8xLx/z8ve+PR5/57zXec01AjWOd9uzXXqlnEkWZIkSeowJEuSJEkdhmRJkiSpw5AsSZIkdRiSJUmSpA5DsiRJktRhSJYkSZI6DMmSJElShyFZkiRJ6jAkS5IkSR2GZEmSJKnDkCxJkiR1TBSSk+yf5JIka5McOcP92yb5YHv/V5PsOnbfUe35S5I8Zf5KlyRJkhbGnCE5yTLgOOCpwB7AoUn26DzsBcBVVXVv4O+Av2qfuwdwCLAnsD/w9vb7SZIkSYM1yUjyPsDaqrq0qq4HTgYO7DzmQOC97e1/BZ6QJO35k6vquqr6DrC2/X6SJEnSYE0SkncCLh87Xteem/ExVbUeuBq4y4TPlSRJkgYlVbX5ByQHAU+pqhe2x78H7FNVLxt7zEXtY9a1x9+mGTFeBXylqt7Xnn83cGpVndL5Mw4HDm8P7wtcMg9/t3E7Aj+a5++5EKxzflnn/JqGOqehRrDO+Wad88s658801Ai37jrvUVXLZ7pj6wmevA7YZex4Z+CKWR6zLsnWwB2AKyd8LlV1PHD8BLXcLEnWVNXKhfr+88U655d1zq9pqHMaagTrnG/WOb+sc/5MQ41gnbOZZLrFOcDuSXZLsg3NQrzVncesBg5rbz8b+Fw1Q9SrgUPa7he7AbsDZ89P6ZIkSdLCmHMkuarWJ3kpcBqwDDihqi5KsgpYU1WrgXcDJyVZSzOCfEj73IuSfAi4GFgPvKSqbligv4skSZI0LyaZbkFVnQqc2jl39NjtXwAHzfLc1wGvuwU1zocFm8oxz6xzflnn/JqGOqehRrDO+Wad88s658801AjWOaM5F+5JkiRJtzZuSy1JkiR1GJIlSZKkjonmJGv+JXnI5u6vqq8tVi1afEluC6yoqvnuCS7NuyQPq6pz+q5DkhaTc5J7kuT0zdxdVfX4RStGiyrJM4C/Abapqt2S7AWsqqoDei4NgCT/Dsz6wjCUOkeSBPhd4J5VtSrJCuBXq2pQ7SaT3AtYV1XXJXks8CDgn6vqJ/1WNrMke9B0KjoUuHpIPVSTbAXsW1Vn9l3LbJLceXP3V9WVi1XLUpLkV2k2KyvgnKr6355LWjKS7AIcUlV/3XctXUl2Au7B2OBuVX1hwf/cpRiSk9wNeD3wa1X11PbF/hFV9e6eS5s6Sd7K5gPTyxexnDkluQ/wDuBuVfWAJA8CDqiqv+y5tJskORd4PPD5qtq7PXdBVT2o38oaSR6zufur6ozFqmUSSd4B3Ag8vqrun+ROwKer6mE9l7aRJOcDK4FdaVpqrgbuW1VP67OucUnuQROKD6Vp23kPYGVVXdZnXTNJ8pWqekTfdcwmyXdoXjszw91VVfdc5JJmNE0fipO8EDga+BzN/9fH0AwwnNBrYR1JjgVeW1Xr2+MdgLdU1fP6rWxTSXak6U52KLAT8NGqelW/VW0syV8BB9O0Ex61Ea7F+NlcqtMt3gOcCPx5e/xfwAdp+jkPTpIHAHsA243OVdU/91fRRtb0XcAW+kfgT4B3AVTVBUk+AAwmJAPrq+rqZgB0eIYWgifw8Kp6SJLzAKrqqnbjo6G5se07/5vA31fVW0c1D0GSM2l2Sz0ZeHZVfSvJd4YYkFufTvJbwEdqgKM9VbVb3zVM6G/a/z4L+FXgfe3xocBlfRS0GX8C7F1VPwZIchfgTGBQIZkmW301yfNo/p++tf0ahCS/Avwm8DvAfYCP0lyJ27nXwmb3TJoBhesW+w9eqiF5x6r6UJKj4KYNUQa5iUmSY4DH0oTkU4GnAl8CBhGSq+q9fdewhW5XVWd3Auj6voqZxX8m+R1gWZLdgZfTvNAPSlvbG9j0A9wgRsDG/DLJMtrRsCTLaUaWh+aXSQ6l2Z30Ge252/RYT9cPgZ2BuwHLgW+xmRHGAXglsD1wQ5JraUYWq6p26LesTbVXN3Zn49+jBb9UPInRh+Ikx1bVfmN3/XuSQdQ4Zh1wzdjxNcDlPdUyq6o6Kslnga8CVwH7VdXanssa9wOa3Y9fA3ypqqr98D5Ul9K8VhqS58nP2k+YozfNfYGr+y1pVs8GHgycV1XPa6eK/FPPNW2iDR5/xqaBaWhzp3/Uzv0c/ds/G/hevyVt4mU0VzmuA/6F5tL7sb1WNLMTgWOAvwMeBzyPmS8d9+0faEZC7prkdTS/U6/pt6QZPQ94MfC6qvpOkt3YMGrXu6o6MMkdgN8CXpvk3sAdk+wztPndAFX1K33XMIl2isARNB9Azgf2Bb5CM+VqSJYnuWdVXQrQ/nwu77mmrv+hGaH9N5rX+AOBs5O8EqCq3txncSNJ9gPeAqwCHgi8Lcnzq+qKfiu7yatp1hu8A/hAkg/2XM+MxqZ7/hw4v/3gcVNQXozpnkt1TvJDaC5tPAD4T5pf9GdX1QW9FjaDJGdX1T7tPNXH0Xwy/s+q2rPn0jaS5NM0U1ZeRfNGfxjww6r6s14L60hyT5odeR5J8wn+O8BzBnzJeLCSnFtVD01yYVU9sD33xar69b5r60pyP+AJNCH+s1X1jZ5L2qx2ZHGXIb4mjbQf2A+meTPdpap26bmkjYwt2Nytqo5tFx3dfWiBPsmFwMOAs6pqr/Zn9bVVdXDPpW0kyf40r52Xtqd2BV5UVaf1VlRHe+V1VlX12sWqZXOSnA08t6oubo+fBby+qu7Xb2Uba98vD6X5Hd+dZlDko1X1X70W1kpy2ObuX4wr3UsyJAMk2Rq4L82b5iVV9cueS5pRkrez4VPdHwP/B5w/tAn+Y4HppgVmSc6oqs0u8upLku2BrarqmjkfvEimaYEMQJIvA78O/CvNQpn/Ad5YVffttbAxbZeDC6rqAX3XMpcknwcOoLmCdz7N9IYzquqVfdY1iST3qKr/7ruOcVO0YPOcqnpYu3Dz4W13k/Oraq++a+tKsi0wCnLf7GMO6KTaf++fDHE+epJlVXVD59xdRnOphyjJA2nmKP92Vd2r73rGte/nvxj9P22n121bVT9f6D97SU63aD+1jbtPkquBC6vqB33UNJuq+sP25juTfArYYaCjS6MPGd9L8nTgCprLh4PSzj3/a+Co0Ytnkq9V1Wb7Ui+Sv5n7IYPyCuB2NHOmj6W50rHZT/aLrapuTPL1JCuq6rt91zOHO1TVT9vL7ydW1TFJBvO7nuREZv8QV8ALFrGcSUzLgs11Se4IfAz4TJKraF4/ByXJ7Wjmed+jqv4gye5J7ltVHx9AbUcDH6qqb7ZB/pPAXsD6JL9TVf/Rb4Wb2DHJ64Gdqmr/tB22GGjzAICquhA4qv0ams8CT6QZRAS4LfBpmivGC2pJhmSaF/NHAKNexI8FzqIJy6uq6qS+CutqJ8t/rqqurqrLktwxyTOr6mN919bxl+18xT+mmcqyA/BH/ZY0o4todpL8dJKDq+lFOoh5tGMLZI6oqreM35fkCGBQXSVqw+YR/0czn3ao7g5c1F7i/Nno5NBG5oGtk9wd+G02dN4ZkpnC0AqaD0vLFrmWSUzFgs2qGi2I+os0/fHvAHyqx5JmcyJwLs17JzSL5D7MzD8Xi+1gNqzbOIzmNX45TWeG9wJDC8nvYcAdtrKhPeFNp8aOa2gjycB2VTUKyFTV/7Uf6hbcUg3JNwL3r6rvw01z694BPBz4AjCYkAwcU1UfHR1U1U/aeVeDCsljowlX04woDtX6qvrTJL8NfDHJ7zO8FfqH0SzqGPfcGc71KslngIOq3eyivbx5clU9pd/KNjGIeYgTWEWzSPNLVXVOOx/wWz3XdJOqOmV0u63t1cB+wBsZyJt7x1Qs2GwXjl9UVddU1Rlp2m/tTdP5YEjuVVUHtx1YqKpr23nfQ3D92LSKpwD/0l56/0Y7tXJoht5hq7sx0FY0H95fBQymLeWYnyV5SLU7ESd5KHDtYvzBQ/zhmg+7jgJy6wfAfarqyiRDm5u81QznBvfvkuS9wBGdwPS3VfX8fivbRADaF6iLaLpHrOi3pEb75vM7wG5JVo/d9SvAEOeq7Vhju8G1l7Pv2mdBM6kp6etcVR+mGZkbHV9K00liMJLcn2b0a2+aaUsvrnZDhKGpqve3C55HCzafOdAFm+8Axqd7/WyGc0NwfZLbsmFk/l700HJrFtel2U/g+zSDNOObXSzKiOIWGnSHrdrQZ3or4Pdo+k+fDzx9tNhwYI4APpxkNE3p7jRXFxbc4MLYPPliko+z4Q3pt4AvtJO/h7YF7JokbwaOo/mFehnNJa+hedAMgWnvPguaxQtHN6rqoiSPpmlEPgRn0rSj2xH427Hz1wCDmZs65sbxub5pdmMb2qj86A3orcD9gW1opgb8rAbWLzfJdjRTwfZk4zaKg/igmeTDNCNMf0MzleoGYIfRYGINcxvlbwE/pX0vG+jc9IwvLmvn0Q/xvfcYmmkguyR5P/AomitcQ3AEzQLi5cDfVdV3AJI8jWGOfL6SZkfNe7ULoJfTXOkYhCS3AZ5P83v+JeDAqvp2v1XNrA3y29AsKB01Y/jmYjVjWJLdLdpLRM8CHt2e+jFNa6CX9FfVzNrg/v9oJqWHZjL6X1bVzzb7xEWW5OvAY6vqqvb4zjQr8x/Yb2WNJI+vqs/NsGgTgKr6yGLXNO2yoSXUaKR2P+DwIbWEAkiyhqY7zCjk/T6we1W9utfCOtoQ+k2aqwmraNqXfaOqjui1sFaSyxiblzg6PTqugW0ik+RlNMHu+zSBfrSZyCC2dx9J8hHg8zSjxwB/CDyuqoby4f0m7ejnvjT/L8+qqh/1XNJUSfIw4PKq+t/2g9CLaAbpLgaOHsoHzTNANF4AAB0TSURBVCTraDbZ+ntgkw+VQ3u/TI9b0C/JkAyQZC/adiY0vXJPqaq39VvV9Grn9h5F82kemr3eXzeURZBJXtt2CzhxhrtrCKN1Sb5UVY9Ocg0zLJoY2sgnQJId2fCm+ZUhvmkmWVNVK7Nxe8Izq2rBVz5viSTnVdXeozrb0ZzTangb8mxWkj2r6qIB1LGWpsPFEKcq3aSdovQPNJuHFM1K/VcMrdNSu6j96LHjrYCTqup3eyxrI22IP4ZmAKxoRkFXDeVnIMnXgCe2Uzv3o9ni/WU0nTjuX1WDGE1O8h4208lmCO+X45K8luZq66JvQT/ESz43W5L70IwoHUozevxBmg8Cg1toluTvq+oVmaV37tBW5lfVP7cjdo+nCUzPGtLcpao6pv3vkLswbA/D3yksyf3aVkujOZOjeWAr2svZX+urtln8PE3rr/OTvIlmSsv2Pdc0k9HlwZ+08yv/l2bDhmlzEsOYT3s5A5rnOZs2DB/Sdx0TWJHkqKp6Q9tm7cPA0H7XT6ZZfD+ay/+7NO/zT+ytoo0tGxstPhg4vl0Qe0qaPtmDUFXPneRxSQ6rRdiwYwKjLejXJ/kFiziwtKRGkpPcCHwReEG1+6QnuXRolwmhWZ1ZVecmmXEzjqEsRkqyQzW9Xe880/1DuXw00rZSO5Fmnu8/0ryZH1lVn+61MAbVr3mzkhxfVYe37aq6amgjn+1c6e/TzFv7I5oWW28fvQYMRZr+yKcAD6L5Gb09zSXYd/Za2BYajYj3+OePNl/Zk2aO4ifYeKvaoWxN/KdV9aZs2Fp3I7UIW+puiXaa4vuBC2kWx32yqv6u36o2lnZTq865NVXV7dbQiyT/CezVdrP4Js30tC+M7qsp2PRo3LS8Zy2kJTWSTPPp8hDg9DQbc5zMQHrkdrUBeRnwB1X1nL7r2YwPAL9Bs5hwpr6KQ/sA8vyqekuSpwB3penveyLNXO++3XXsDX4TQ3lzbwPyVsBrqurLfdczm9EirdqwE9wvGHA7uKr6p/bmGQzv92ZL9D2yMroS8932a5v2C/qvbdyo08aaXquYw9gVI2jaUL4L+DJwxnjbrYE4PckhwIfa42fTfEgain+h+f/2I5oWZV8ESHJvpuCqxwwGk5/ajlq7s/Gi5y8s+J+7lEaSR9rFcM+kmXbxeJpm4x8dwmhiV5LTgGdU1fV91zKbdoRhlwGuGt/E2HzPtwCfr6qP9j3yNVbb92gW78z4wlNVgwp4fS6WmMT4KEeSU6pqUO3URjb3wQiG8+FoUkMZXUpyUDVt9TZ7rk/tQMgbq+pP+q5lNrNcMRoZxJWjsXUcobnsPuo5vAz4vyGt52i77dydZov0n7Xn7gPcfmAfOOY0oN/1F9J0ONmZplXdvjRrZBb8Z3OpjSQD0P5gvh94fztN4CDgSIYxmth1GfDlNH1zx3cLG8wbZ1VVko8CD53zwf07N8mngd2Ao9I07h/KLlzfq6pVfRexBT6d5LfoYbHEhMY/bAx5ZHbQc9BvhqF8oD+Ksb7TmznXm6q6Ic3GB4NVVY9rrxwdVFUf7LuemQx9Hce4qjprhnP/1Uct82AoI8lHAA+j6bjyuCT3Y5GuGi7JkDyunTP7rvZriK5ov7Zi2G+mZyV5WG3YqnioXkCzkvjSqvp5uxr6psV8Pa/MH8oLzqRGiyVuSHItw+vCUbPcHpShXSGYTeey+yZGo2BVte/iVDSzJE8FngbslOQfxu7agaat1dCc1w6CfJiNB0IG02armt7NL6FZBDc4Mywm3si0jdBOkaFMt/tFVf0iCUm2bX8W7rsYf/CSnG4xjZJsXwPrjTwuycU0i2Quo3mhH2RP0rn0efkoyZ2HttBxmqXZ5nX0s3hb4OejuxhWmAcY/K6V03DZHSDJg2k+CK8Cjh676xrg9Gp7uQ9FBtyWclyS/0czj/aDbBzme3/NmmUx8fgGLYP42Zw2Se4GvB74tap6apI9gEdU1aC2oW+vZD8PeAXNFNqrgNtU1dMW/M82JPcrySOAd9PMV1rRvgG8qKr+sOfSNtJ2ENjE2KKpqTCU+cnTIskBNJuIQDPH++N91jPNZvrZ8+fx5kvTZzrAfdpTl9Qi7cK1FCX5zgynawjdoZLsA3y3qv63PT6MZqH+ZcBfDCHIT6Mkn6RZ2P7nVfXgNBugnFcD2SRsJm1HsDsAn1qMtVxbLfQfoDn9PfAUmr7OVNXX2RBKBqMNw7sAj29v/5zp/PnxU+GEkryRZi7Yxe3XEe053TxbtaPHAKNdKwc55S3JA5L8dpLfH331XdMMHkmzLfVxwNuB/0qzgcOgJNk5yUeT/CDJ95OckmTnvuvqqqrdZvjqPSC33kk7F779N34DzYL8q2l2BdXNs2NVfYh23U5VrWfDosjeJdkuySuSvC3Ji5JsXVVnVNXqxWp2MMgX6Fubqrq8aSBxk8H8kI4kOYZmy9/70nzyvA3wPuBRfdalBfU0mp6fN8JN0wXOo1kEqy33t8BX0mxPXTS7gb6u35I21f6uPxbYAzgVeCrNzmb/3GNZM3kz8OSqugRu6iDwLwxvgfGJNK00D2qPn9Oee1JvFc0izSY3e7Bxm60h/LtPxSYdU+hn7bqdgps6cwypVd17aTZh+iLN69AeNAM3i8aQ3L/LkzwSqDS7hr2cDf01h+Q3gb1pd2CqqivazhHTZigr86fFHYHRm9Md+ixk2tXAd60c82zgwTSXXZ/Xzlv8pzme04fbjAIyNB0E2ikYQ7O8qsbnJb8nySt6q2YWA/9wtKwdRVwPPAE4fOw+c8zN90pgNXCvJF8GltP8/g/FHqOpH0neDZy92AX4w9W/F9M0cN8JWEfTpu4lvVY0s+vbVnCjT5xD3PaXJKcAJ9DsFrVJ67e+V+ZPmTfQrMw/nSbU7UfTYktbIMl2NL/n96bZzeyd7Zv9UF3bdjtYn2QH4AcMs8XemvaN86T2+HdpNj0amh8leQ7NKDc0/ft/3GM9sxnyh6OltknHIFTV19o5vveleY0f2rz+m2qpZhfDRS/AhXuaSJJX0ex28ySa8PR84ANV9dZeC+tI8kSaVbD70rRcek9VfbPfqqZXkrvT9KcM8NXRwhlNLskH2fiS4WVVNbiRxJEkbwdeTbN76R8D/wecX1XP2+wTF1mSbWkGFB5N8/P5BZrtyK/b7BMXWZIVwNuAR9Bc1j6TpsvJoBY9Jzm7qvZJci7NttTXAP9ZVXv2XBqwtDbpGIokz5rh9NXAhVX1g8Wup2usgxFs3MVo0ToYGZJ7lmQ34GXAroyN7FfVAX3VNJskTwKeTPMDelpVfabnkmaV5A40IzZ/DlwO/CPwvoF9Sh60WXqSXg3898BHQgclyYVjlwy3Bs7uqw3hlkqyK7BDVV3QcylaYNPy4UjzJ8knaD68jVrrPRY4i6ZjzKqqOmmWp95qGJJ7luTrNC3gLmRsZ7iqOqO3ojajvfw6HuYH13qnXYjwHOD3aDZqeT/NaNMDq+qxPZY2VZKcBTwEuIDmg9ED2tt3AV5cA9zmfYi6vbn77NU9iSS/CXyuqq5uj+8IPLaqPtZvZRtL8hvAscA9aF6Thtof+x9mOH01sKaq/m2x65mEH45uHZL8O/DCqvp+e3w34B3AC4EvVNUD+qxvCAzJPUvy1ap6eN91zCXJi2ia919LE+ZHb0iDmquY5CPA/WjmKb6nqr43dt+aqlrZW3FTJsnJwLHV7lDYNpr/E5pg8pGq2qvP+qbFEC4Zbokk53f/bYfYzznJWuBZNJeGB/tGluR4mtek0XbZvwVcRNNS89IhTb1pL78/mmZayJeq6qM9l6QFNH6Vqz0Oze/TA4b4O98HF+717y3tquJPAzfNpRvgHKtXAXtW1Y/6LmQOb6uqz810hwF5i92vxrbwrqqLk+xdVZf2sYBiWlXVsr5r2EIz9T8f4nvF5TRzZgcbkFv3pukvvx4gyTtoXu+fRHMFcRDa6Rb3ZsMCwxcleWJVDXEhuebHF5N8nI0/wH2hXZj/k/7KGo4hvvDd2jyQZlrA49kw3aLa4yH5Nhu2/R2c8QUIMy1GqKqPLG5FS8Il7Rv6ye3xwTQbNmzL2KpjLTlrkryZZpOOolkzMcSuEX8KnJrkDDYeYHhzfyXNaCdgezZ0YdieZhvgG5IMaZHhY4AHjD50tH3RBxPitSBeQnM15tHt8dnA3duFkY/rraoBMST37zeBey7W7jG3wFHAmUm+ysZvSC/vr6SNPGMz9xVgSN5yzwX+EHgFzdSAL9FcUfglvoAuZS8D/h/wQZp/96G2pXwdzeKy7YBteq5lc94EnJ/k82xopfj6drTuP/osrOMSYAUw6rqxC80aBC1RbVvXbwMPp9nc6DvAKf1WNSzOSe5Z2x7qZUNot7I5Sc6mCUndBYbv7a0oLbgktwVWjG/aIA3BNK0xaFsp7kMTks+uqit6Lukm7eKtotks6GE0o4lFE5zOrKon9lieFkDbOu8QNvTs/iDwqqq6R6+FDZAjyf27G/DNJOew8Qjt0FrAra+qV/ZdxGySPKeq3pdkxhoHeAl28JIcAPw1zSjdbkn2omkLNLSfTc2DJH9fVa8YC00bGeC/+38kefLQu6y0i6GeQHPFcFWSFUn2qapF3z1sFn/TdwFadN+k6dv+jKpaC5Dkj/otaZgMyf07pu8CJnR6ksOBf2fjMD+UFnCjHQCncavsoTqGZvTr8wBVdX7bGkpL06gn6rSEppcAf9rO6/0lA+0WAryd5urb42k6BF1Dc0n7YX0WNdJtN9pt86kl6bdoRpJPT/IpmnUnrsaegdMtNJEk35nh9OBawGn+jNoTjrcCSnJBVT2o79q0MJIsA95bVc/pu5ZbKsme491Zeqzja1X1kM7v0der6sF91zauHQQ5loG3+dT8aefFP5Nm2sXjgfcCHx361ZnF5KfFniW5hg2XNrcBbgP8bGijIVW1W981TGKadjCcAv+Z5HeAZUl2B15Os6Wulqi248LyJNtMwWLiuZxEsxlO337ZfvgYdY1Yzti6jgH5E6ajzafmSdvF4v3A+5PcGTgIOJJmsa4wJPeuqjaaHpDkmTSXuAclye/PdL6q/nmxa5nDx2h2MPx3hvlGNE1eRrOt93XAB4DTaEaatLRdBnw5yWo2bIIyjfP6h3L5+B+AjwJ3TfI64Nk03UOGZtBtPrWw2qmT72q/1HK6xQAlOauq9u27jnFJ3jp2uB3NQpSvVdWzeyppRtOyg+E0SHJQVX14rnNaWtrNjTZRVa9d7FpuiSFt/53kfjSvmQE+W1Xf6LmkTSTZGzgRGGqbT2nRGZJ71tn4YitgJfCYqnpETyVNJMkdgJOGNo2hnR6wO8PfwXDwZgoZQwoeWlhJtm8vx06lofysJjmpqn5vrnN9s82ntCmnW/RvfBOM9TSXOg/sp5Qt8nOaMDo007KD4WAleSrwNGCnJP8wdtcOND+jWsKSPIJmytLtgRVJHgy8qKr+sN/KtthQ5lTvOX7Qzk9+aE+1bM6g23xKfTAk96yqntd3DZPo9E7dCtgD+FB/Fc1qWnYwHLIrgDXAAWy8HfE1gL00l76/B54CrAaoqq8n2a/fkjaV5FHA+VX1syTPoVmk95aq+m+AvqesJTkKeDVw2yQ/ZcMc6euB43srbHZDb/MpLTqnW/SsXen8B2zajeH5fdU0kySPGTtcD/x3Va3rq57ZTMsOhtMgyW2q6pd916HFNUvrvyG2LLsAeDDwIJpOFu8GnlVVj9nsExdZkjdU1VF91zEX23xKm3IkuX//RrPzzX8AN/Rcy6y6DecHbFp2MJwGuyZ5A81Vg+1GJ33TXPIuT/JIoJJsQ9P6b3ALzWimB1SSA2lGkN+d5LC+i+qqqqOS3Ilmetr479EX+qtqU9PS5lNaTIbk/t2uqv6s7yLm0i4w/CvgrjSXDYe6u9W07GA4DU6k+f/5d8DjgOcxnLZaWjgvBt4C7ASso1kE+5JeK5rZNe2UhucA+7VzfW/Tc02bSPJC4AhgZ+B8YF/gKwxknUSSP62qN7W3N+pek+T1VfXq/qqT+uV0i54l+UvgzKo6te9aNifJWpp93oc4oqQFkOTcqnpokgur6oHtuS9W1a/3XZuU5FeB3wHOqaovJlkBPHZovduTXEizBfVZVbVX2w7utVV1cM+lARt3Ael2BBlKhxCpL44k9+8I4NVJrgN+yXBHaL8/DQE5yb7AW4H70+xguIwB7mA4JX6RZCvgW0leCvwPzZUELWHTsmtlVf0v8Oax4+8CgwrIrV9U1S+SkGTbqvpmkvv2XdSYzHJ7pmPpVsWQ3LPujntdSfasqosWq57NWNMuivsYG8/1/Uh/Jc3obcAhwIdpek7/PsNsVTcNXgHcjmZO6rE0Uy4GN+dT827Qu1Ym+VJVPTrJNWzouAPDHWBYl+SONP9fP5PkKpoOMkNRs9ye6Vi6VXG6xcAN5XJXkhNnOF0D7MKxpqpWJrmgqh7Unjuzqh7Zd23SNHDXyoXTdgm6A/CpobSpTHIDzfbjAW7Lhq2pA2xXVYOb5y0tFkeSh28Ql7vm6uec5KiqesNi1bMZP29X5J+f5E3A94Dte65pKiX5DHBQVf2kPb4TcHJVPaXfyrTA3tJuTe2ulfOgnQJ2UVVdU1VnJPkVYG+a7Z97V1XL+q5BGipHkgduKCPJcxlKnUnuAXyfZj7yH9GM2ry9qtb2WtgUGu+Tu7lzWlratn+/B3ybsV0rq2oQ3RimTZLzgIdU+2bbzvNfM4TXS0mb50iy5kuvI95JVlTVd0e7bQG/AF7bZ01LwI2j/69w0wcQP1Uvfe5aOb9SY6NRVXVjEt97pSmwVd8FaE7T8kbVd3j62OhGklP6LGQJ+XPgS0lOSnIS8AVg8DuH6Rb7OnDHvotYQi5N8vIkt2m/jgAu7bsoSXMzJPcsyWc3d66q9l3cim62vudOj//57gg3D6rqU8BDgA8CHwIeWlWnje5PsmdftWlBjXatPC3J6tFX30VNsRcDj6RpobgOeDhweK8VSZqIl3x6kmQ7mvZaO7YLokYhbwfg13or7Ob78NwPWVCba2Okm6mqfgR8fJa7T6IJ0Vpa3LVyHlXVD2jaUs5oQIueJXW4cK8n7SW3V9AE4vGemT8F/rGq3tZLYbNIshz4AzbdYGAQLeDmaGM0xN6pU89FfNItN5RFz5I25UhyT6rqLTStll5WVW/tu54J/BvwReA/gBt6rmUTtjHqhZ+wl6DOJh3bALfBXSsXUt9T1STNwpDcvxOSvAZYUVWHJ9kduG9VzXaJuy+3q6o/67sISQuruwtokmcC+/RUzq2BHzalgXLhXv9OoOlgMdoRbh3wl/2VM6uPJ3la30VoUKal84pugar6GGCP5IXjSLI0UI4k9+9eVXVwkkMBquraJEN80TwCeHWS64Bf4lzfJS/JZ6vqCbOdm6LOK9oCSZ41drgVsBJHOxdS34ueJc3CkNy/65PclvZNKMm9GNsKdii6l2C1dC3BzivaMs8Yu70euAw4sJ9Spt9ci56r6vX9VCZpLobk/h0DfArYJcn7gUcBz+21ojFJ7ldV30wy4+rrqvraYtekBfciNnReGf/3/SlwXC8VadFU1fP6rmGJGfSiZ0mzswXcACS5C7AvzYjdWW1v2kFIcny7oPD0Ge6uqnKu4hI1RZ1XNI+G3u5x2iQ5v6r26rsOSVvOkNyzJKuq6uix462Ak6rqd3ssSyLJ9sAfMfzOK5pHSc6kGfk8l7GRz6pyu/ebIclfAmdW1al91yJpyxiSe5bkPcAlVfWGJNvSLOL4WlX9Ra+FdbTzVP8QeDTN/OkvAu+sql/0WpgWTJIP0gSl36+qB7Rz57/iqNjS5sjn/Gr7Tm9Ps9bERc/SFDEk96ztZPF+4ELgccAnq+rv+q1qU0k+BFwDvK89dShwp6o6qL+qtJCSrKmqleM76yX5elU9uO/atHAc+ZSkhgv3etJZCPcW4F3Al4EzkjxkgAvi7tsJR6cn+Xpv1WgxTEXnFc072z3OAxc9S9PPkNyfv+0cXwXs0Z4vhte8/7wk+1bVWQBJHk4T6rV0DbrzihbGXO0ek+xZVRctVj1T7JXA4Wz6Wg/DfI2X1OF0C21WkgtpXtBvA9wX+G57fA/g4qp6QI/laYENufOK+pHka1U14+ioJC0ljiT3LMnrgTdV1U/a4zsBf1xVr+m3spv8Rt8FqB9jnVc+0R5vleT9dl651RvijqCD5aJnaXpt1XcB4qmjgAxQVVcBT+uxno1U1X+PfwHX0rzQj760dK1IchRA23nlY8C3+i1JA+Dv/Zb5Z2BP4K3A22im1Z3Ua0WSJuJIcv+WJdm2qq4DaBdKbdtzTZtIcgDN3LpfA35AM93iGzQv/lqange8vw3Kg+28Ig2ci56lKeVIcv/eB3w2yQuSPB/4DPDenmuaybE0c1P/q6p2A56AC/eWpCQPaVfk703TeeVgmhHkM2Zbqa9blev7LmDKnJdk39GBi56l6eHCvQFI8lSa0Bng01V1Ws8lbWKsZ+7Xgb2r6sYkZ1fVPn3Xpvk1yxbkI25FvsQl+WxVPWGuc9o8Fz1L08/pFgNQVZ8EPtl3HXP4SZLbA1+guQT/A2B9zzVpAVTV4/quQYuvXWB2O2DHdgHxaIHeDjTTrLRlXPQsTTlHknuS5EtV9eh2y9Lxf4RBNe5Pcm/gbsD5NIv2tgJ+l2Y05BNVdW6P5WkBTUHnFc2jJEcAr6AJxFeM3fVT4B+r6m29FLZEJLkrsN3ouKq+22M5kiZgSO7J+Fa/Q5bk48Crq+qCzvmVwDFV9Yx+KtNCm+ln1B65S1+Sl1XVW/uuY6mYbdFzVbnoWRo4F+71Z1o+nezaDcgAVbUG2HXxy9EiWta2fgOG23lF8+6EJK9JcjxAkt2TOHXg5nPRszSlnJPcn7smeeVsd1bVmxezmM3YbjP33XbRqlAfRp1XTqT5UPd8htl5RfPrBOBc4JHt8Trgw8DHe6touv2yqn7cbsazVVWdnuSv+i5K0twMyf1ZBtye4e9edU6SP6iqfxw/meQFNG+kWqKq6k3tCv1R55Vjh9h5RfPuXlV1cJJDAarq2iRDf50aMhc9S1PKOck9mZa5nUnuBnyUpjfqKBSvBLYBfrOq/rev2iTNvyRn0k4JqKqHJLkX8C+2e9wyLnqWpp8huSfTsnBvJMnjgFFfz4uq6nN91qOFMy2dV7QwkjwJeA3N9smfBh4FPLeqPt9nXdPGRc/S9DMk9yTJnavqyr7rkLqm7QOc5l+Su9AsNvv/27t7XZnCKAzA74qIiJ+gULoDjVqD6rgMl6BTEqGjFIWIhEpLhEQ0CpWGe9D4S1zAUswhMzs5EsJ8s83zdJM9xZtM886Xb61dSd5098fBkWanqt7v9cKQqnrX3afXnQn4PbZbDKIgs8H8c95iVXWtuz9199PufpLkc1U9Gp1rhgw9w8wZ3AOm5rJ5hX/jVFVd6e6buysAHyd5OzrUDBl6hplz3QJYUVUfktzJHptXuvvqehOxTrubLB4leZfkXJJn3X17bKr5MfQM86ckAyvmsnmFv6uqln/z/UnuZvHSi3tJ0t1Ok/+AoWeYLyUZWGFwbztV1atfPO7uPr+2MAAbQEkGVti8AgC2WwATCvJ2q6obVXVs6fPxqro+MhPACEoyAMt2uvvrjw/d/SXJxYF5AIZQkgFYtm939VuSpKoOJjnwi+8D/JfsSQZg2cMkL6vqfhYvlrmU5MHYSADrZ3APgBVVtZPkQha7sl909/PBkQDWTkkGAIAJ1y0ASFW97u6zVfUti2sWPx9lsSf56KBoAEMoyQAkyaEk6e4jo4MAbALbLQBIVk+PAbaek2QAkuRkVV3e62F331pnGIDRlGQAkmRfksNZ3EEG2Hq2WwCQqnrb3WdG5wDYFO4kA5A4QQZY4SQZgFTVie7+PDoHwKZQkgEAYMJ1CwAAmFCSAQBgQkkGAIAJJRkAACaUZAAAmPgO0tuOgr5rVjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = pd.Series(model.feature_importances_)\n",
    "importance.index = training_vars\n",
    "importance.sort_values(inplace=True, ascending=False)\n",
    "importance.plot.bar(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
